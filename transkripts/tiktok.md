Immer radikalere Inhalte, immer mehr Gewalt. Auf digitalen Plattformen werden hasserfüllte Inhalte durch den Algorithmus verstärkt. Dies trifft auch auf TikTok zu, zeigt eine neue britische Studie. Ruth Willi hat Digitalredaktor Jürg Tschirren gefragt, wie dieser Mechanismus funktioniere. In den sozialen Medien sind Algorithmen dafür zuständig, was uns gezeigt wird, also eigentlich Computerprogramme. Wie diese Algorithmen jeweils funktionieren, das weiss niemand so genau. Das ist das Geschäftsgeheimnis der einzelnen Plattformen. Und sie rücken natürlich auch nicht heraus, damit nicht jemand einen Vorteil hätte und die eigenen Inhalte so zuschneidern kann, dass der Algorithmus sie bevorzugt. Was man allerdings weiss, ist, dass diese Plattformen, die sozialen Medien, einen so lange wie möglich auf der Seite halten wollen, damit sie eine Werbung anzeigen können. Denn fast alle Plattformen verdienen fast ausschliesslich mit Werbung ihr Geld. Ist die Erkenntnis neu, dass die Vorschläge immer krasser werden? Diese Studie belegt, dass es bei TikTok eben auch so funktioniert, wie es z.B. bei YouTube funktioniert und dort mit ähnlichen Versuchsstudien auch schon nachgewiesen wurde. Man weiss, dass Leute, die sich für bestimmte Themen interessieren, auf sozialen Medien dann immer mehr von diesen Themen zu sehen bekommen und dass das Medium probiert, das auch immer interessanter oder packender zu gestalten. Das kann bedeuten, dass diese Inhalte dann immer extremer werden. Wer ist das Zielpublikum von diesen Algorithmen? Eigentlich alle, die die sozialen Medien brauchen. Also der Algorithmus versucht, allen das zu zeigen, was sie interessiert bzw. von dem der Algorithmus annimmt, dass es einen lange auf der Seite behält. Dabei muss es nicht wirklich darum gehen, jemanden zu radikalisieren oder immer extremere Inhalte zu zeigen, sondern einfach nur darum, jemanden so lange wie möglich auf der Seite zu halten, eben damit diese Person dann Werbung zu sehen bekommt. Die Studie hat ja auch gezeigt, dass der Online-Konsum das Offline-Verhalten prägt. Wie siehst du das? Das ist wissenschaftlich sehr schwer zu belegen, denn man müsste als Kontrollgruppe ja quasi eine Welt haben, in der keine sozialen Medien existieren. Und dann schauen, ist das Verhalten der Leute oder ist es in der Offline-Welt dort eine andere? Ich glaube durchaus, dass soziale Medien beeinflussen können, welche Verhaltensweisen, welche Ansichten wir akzeptieren, was wir auch ablehnen vielleicht. Und man kann davon ausgehen, dass die sozialen Medien bestimmte Themen emotionalisieren, also auf eine subtile, aber sehr schwer fassende Art Einfluss haben. Welche Bemühungen gibt es denn, diesem fatalen Mechanismus entgegenzuwirken? Also im Grunde genommen müssten die sozialen Medien, diese Plattformen einfach ein bisschen langweiliger werden. Allerdings, langweiliger zu werden, das steht in direktem Widerspruch zum Geschäftsmodell dieser Plattformen. Aber es wäre wohl ein erster wichtiger Schritt, die Vorschläge zum Beispiel nicht mehr von einem Algorithmus abhängig zu machen, der einem dann immer extremere Inhalte präsentiert, sondern zum Beispiel nach anderen Massstäben zusammenzustellen, etwa, was haben meine Freunde geschaut. Ausserdem sollten Plattformen in die Pflicht genommen werden, dass sich auf ihnen gar kein extremes Material mehr findet. Aber diese Plattformen sind wohl einfach zu gross, um den Inhalten noch Herr zu werden. Wobei man auch sagen muss, dass die Plattformen bis jetzt immer das eigene Wachstum und damit die Werbeeinnahmen vor das Wohl der Nutzerinnen und Nutzer und auch dem der Gesellschaft gestellt haben. Das sagt Jörg Tschirn von der SRF-Digitalredaktion.

<iframe width="560" height="315" src="https://www.srf.ch/play/embed?urn=urn:srf:audio:16a52080-fed2-4db7-93c7-73310c7da48d&subdivisions=false" allowfullscreen allow="geolocation *; autoplay; encrypted-media"></iframe>